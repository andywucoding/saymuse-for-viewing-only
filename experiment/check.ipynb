{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the JSON file\n",
    "def load_json_file(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Step 2: Read the text file into a single string\n",
    "def load_text_file(text_file_path):\n",
    "    with open(text_file_path, 'r') as file:\n",
    "        text = file.read().lower()  # Convert text to lowercase for case-insensitive comparison\n",
    "    return text\n",
    "\n",
    "# Step 3: Function to check if each label keyword is found in the text\n",
    "def find_missing_keywords(label_keywords, text):\n",
    "    # Return a list of keywords that are not found in the text\n",
    "    missing_keywords = [keyword for keyword in label_keywords if keyword.lower() not in text]\n",
    "    return missing_keywords\n",
    "\n",
    "# Step 4: Process the JSON and check each label's keywords in the text\n",
    "def process_labels(json_data, text):\n",
    "    results = []\n",
    "    for label in json_data['labels']:\n",
    "        label_id = label['label_id']\n",
    "        keywords = label['label_keywords']\n",
    "        \n",
    "        # Find missing keywords\n",
    "        missing_keywords = find_missing_keywords(keywords, text)\n",
    "        \n",
    "        # Only include labels that have missing keywords\n",
    "        if missing_keywords:\n",
    "            results.append({\n",
    "                'label_id': label_id,\n",
    "                'missing_keywords': missing_keywords  # Include only if there are missing keywords\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Step 5: Save the results to a new JSON file or display them\n",
    "def save_results_to_json(results, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = 'label.json'  # Replace with your actual JSON file path\n",
    "text_file_path = 'hmns_1.txt'  # Replace with your actual text file path\n",
    "output_file_path = 'output_results.json'  # Path to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "json_data = load_json_file(json_file_path)\n",
    "text_data = load_text_file(text_file_path)\n",
    "\n",
    "# Process the labels and check keywords\n",
    "results = process_labels(json_data, text_data)\n",
    "\n",
    "# Save the results\n",
    "save_results_to_json(results, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Function to load the data from a text file\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "    return data\n",
    "\n",
    "# Step 2: Function to process the data (split by ---new item--- and clean each item)\n",
    "def split_data(data):\n",
    "    # Split data by the \"---new item--\" marker\n",
    "    items = data.split(\"---new item--\")\n",
    "    \n",
    "    # Clean up each item by stripping excess newlines and spaces\n",
    "    processed_items = []\n",
    "    for item in items:\n",
    "        cleaned_item = \" \".join(item.strip().splitlines())\n",
    "        if cleaned_item:\n",
    "            processed_items.append(cleaned_item)\n",
    "    \n",
    "    return processed_items\n",
    "\n",
    "# Step 3: Function to write processed data line by line into a new text file\n",
    "def write_to_text_file(processed_items, output_file_path):\n",
    "    with open(output_file_path, 'w', newline='\\n') as file:\n",
    "        for item in processed_items:\n",
    "            # Write each item followed by a new line and the \"---new item---\" marker\n",
    "            file.write(item + '\\n\\n')  # Ensure two newlines after the item content\n",
    "            file.write('---new item---\\n\\n')  # Ensure three newlines around the marker for clearer separation\n",
    "\n",
    "# Step 4: Main function to load, process, and write data\n",
    "def main(input_file_path, output_file_path):\n",
    "    # Load the raw data from the input text file\n",
    "    data = load_text_file(input_file_path)\n",
    "    \n",
    "    # Process the data by splitting and cleaning it\n",
    "    processed_items = split_data(data)\n",
    "    \n",
    "    # Write the processed data to the output text file, line by line\n",
    "    write_to_text_file(processed_items, output_file_path)\n",
    "\n",
    "# Step 5: Specify the file paths and run the script\n",
    "input_file_path = 'hmns_1.txt'  # Replace with the path to your input file\n",
    "output_file_path = 'hmns_1_updated.txt'  # Replace with the desired output file path\n",
    "\n",
    "# Run the script\n",
    "main(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning process completed. Cleaned data saved to 'cleaned_label.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "with open('label.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Function to clean the labels by removing 'minKeywords' key\n",
    "def clean_labels(data):\n",
    "    for label in data.get('labels', []):\n",
    "        # Remove the 'minKeywords' key if it exists\n",
    "        if 'minKeywords' in label:\n",
    "            del label['minKeywords']\n",
    "        # You can also check for 'label_keywords' if needed and add logic to handle that\n",
    "        if 'label_keywords' in label:\n",
    "            # If 'label_keywords' is required and missing, add a default value (empty or calculated)\n",
    "            del label['label_keywords']\n",
    "    return data\n",
    "\n",
    "# Clean the data\n",
    "cleaned_data = clean_labels(data)\n",
    "\n",
    "# Save the cleaned JSON back to a file\n",
    "with open('cleaned_label.json', 'w') as f:\n",
    "    json.dump(cleaned_data, f, indent=4)\n",
    "\n",
    "print(\"Cleaning process completed. Cleaned data saved to 'cleaned_label.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
